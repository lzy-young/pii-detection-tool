from vllm import LLM, SamplingParams
from transformers import AutoTokenizer
import torch
from argparse import ArgumentParser
import os
import re,gc
import json
from itertools import islice
import datasets

def is_only_special_chars(text):
    """æ£€æŸ¥æ˜¯å¦åªåŒ…å«éå­—æ¯æ•°å­—å­—ç¬¦"""
    if not text or not text.strip():
        return True
    
    # åªåŒ¹é…å­—æ¯å’Œæ•°å­—ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¯´æ˜åªæœ‰ç‰¹æ®Šå­—ç¬¦
    return not re.search(r'[a-zA-Z0-9]', text.strip())

def parse_args():
    parser = ArgumentParser(description="Process some integers.")
    parser.add_argument('--data_path', type=str,required=True, help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--export_path', type=str, help='å¯¼å‡ºè·¯å¾„')
    parser.add_argument('--model_path', type=str, default='starpii', help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--evaluate_device', type=str, default='cuda:0', help='è¯„ä¼°è®¾å¤‡')
    parser.add_argument('--batch_size', type=int, default=1000, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--tensor_parallel_size', type=int, default=1, help='å¼ é‡å¹¶è¡Œå¤§å°')
    parser.add_argument('--gpu_memory_utilization', type=float, default=0.80, help='GPUå†…å­˜åˆ©ç”¨ç‡')
    parser.add_argument('--seed', type=int, default=42, help='éšæœºç§å­')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œå¤„ç†å°‘é‡æ•°æ®å¹¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯')
    return parser.parse_args()


def create_jsonl_prompt(text):
    """åˆ›å»ºè¦æ±‚JSONLè¾“å‡ºçš„æç¤ºè¯ï¼ˆå¼ºåŒ–å¬å›ï¼‰"""
    prompt = f"""TASK: Named Entity Recognition (OntoNotes) and output in JSONL format.
======================================================================================
INSTRUCTIONS:
- Extract ALL named entities that appear in the INPUT text. Do not miss any mention.
- Output ONLY JSONL: one JSON object per line with fields "value" and "label".
- Do NOT output explanations, thoughts, or any extra text.
- If there is no entity, output nothing (produce zero lines).
- Span rules:
  * Use the surface text exactly as it appears, but remove surrounding quotes and trailing punctuation (, . ; : " ').
  * Keep multi-word entities (e.g., "New York", "United Nations").
  * For possessives like "John's", output "John".
- Label with ONLY these categories:
  [PERSON]: Person names (including fictional).
  [NORP]  : Nationalities, religious or political groups (e.g., Americans, French, Catholics, Democrats).
  [GPE]   : Countries, cities, states (e.g., China, Paris, Texas).
  [FAC]   : Buildings, airports, highways, bridges, landmarks (e.g., White House, Golden Gate Bridge).
  [ORG]   : Companies, agencies, institutions (e.g., Google, United Nations).
  [LOC]   : Non-GPE locations, mountain ranges, bodies of water (e.g., Himalayas, Pacific Ocean).
- Disambiguation:
  * Demonyms/groups -> NORP (e.g., Americans, French, Democrats).
  * Geopolitical places -> GPE (e.g., China, Paris).
  * Natural/physical places not tied to governments -> LOC (e.g., Pacific Ocean).
  * Man-made facilities -> FAC (e.g., White House).
  * Organizations -> ORG.
======================================================================================
EXAMPLES:
INPUT: <B> The French and the Germans met in Paris and visited the White House. <E>
OUTPUT:
{{"value": "French", "label": "NORP"}}
{{"value": "Germans", "label": "NORP"}}
{{"value": "Paris", "label": "GPE"}}
{{"value": "White House", "label": "FAC"}}
<END>

INPUT: <B> Americans protested near the United Nations in New York, then crossed the Golden Gate Bridge. <E>
OUTPUT:
{{"value": "Americans", "label": "NORP"}}
{{"value": "United Nations", "label": "ORG"}}
{{"value": "New York", "label": "GPE"}}
{{"value": "Golden Gate Bridge", "label": "FAC"}}
<END>
======================================================================================
INPUT:
<B> {text} <E>
OUTPUT:
"""
    return prompt


def create_y(labels):
    res={'PERSON':[],'NORP':[],'GPE':[],'FAC':[],'TIME':[],'ORG':[],'LOC':[]}
    for label in labels:
        if label['label'] in ['PERSON', 'NORP', 'GPE', 'FAC', 'ORG', 'LOC']:
            res[label['label']].append(label['text'].replace(' ',''))
    return res

def convert_to_jsonl(outputs):
    jsonl_lines=[]
    lines=outputs.strip().split("\n")
    if len(lines)==0 or len(outputs.strip())==0:
        return jsonl_lines
    for line in lines:
        try:
            obj=json.loads(line)
            if obj.get("value", None) is not None and obj.get("label", None) is not None:
                jsonl_lines.append(obj)
        except json.JSONDecodeError:
            continue
    return jsonl_lines


def calculate_metrics(results, labels):
    # å°†ç»“æœè½¬æ¢ä¸ºé›†åˆ (å»é‡å¹¶ä¾¿äºè®¡ç®—)
    metrics = {}
    tp=fp=fn=0
    results_sets={}
    for type in results.keys():
        results_sets[type] = set(results.get(type, []))

    # å°†æ ‡ç­¾è½¬æ¢ä¸ºé›†åˆ
    labels_sets={}
    for type in labels.keys():
        labels_sets[type] = set(labels.get(type, []))
    
    all_preds=set()
    all_labels=set()
    for entity_type in ['PERSON', 'NORP', 'GPE', 'FAC', 'ORG', 'LOC']:
        all_preds.update(results_sets[entity_type])
        all_labels.update(labels_sets[entity_type])
    fn=len(all_labels - all_preds)  # è®¡ç®—æœªé¢„æµ‹çš„å®é™…æ ‡ç­¾æ•°é‡

    for entity_type in ['PERSON', 'NORP', 'GPE', 'FAC', 'ORG', 'LOC']:
        predicted = results_sets[entity_type]
        actual = labels_sets[entity_type]
        
        # ä½¿ç”¨é›†åˆè¿ç®—è®¡ç®—æŒ‡æ ‡
        tp += len(predicted & actual)  # äº¤é›†
        fp += len(predicted - actual)  # é¢„æµ‹ä½†ä¸åœ¨å®é™…ä¸­
        # fn += len(actual - predicted)  # å®é™…ä½†æœªé¢„æµ‹
        # è®¡ç®—ç²¾ç¡®ç‡å’Œå¬å›ç‡
    precision = tp / (tp+fp) if (tp+fp) > 0 else 0
    recall = tp / (tp+fn) if (tp+fn) > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
    metrics = {
            'tp': tp,
            'fp': fp,
            'fn': fn
        }
    
    return metrics

def batched(iterable,n):
    it = iter(iterable)
    while True:
        batch=list(islice(it, n))
        if not batch:
            break
        yield batch


def update_results(results_file,results,batch_cnt,completed=False):
    if not os.path.exists(results_file):
        results_data={'batches':{},'batch_cnt':0,'completed':False}
    else:
        with open(results_file,'r',encoding='utf-8') as rf:
            results_data=json.load(rf)
    if completed:
        results_data['completed']=True
        with open(results_file,'w',encoding='utf-8') as wf:
            json.dump(results_data,wf,indent=4)
            return
    results_data['batch_cnt']=batch_cnt
    results_data['batches'][f'batch_{batch_cnt}']=results
    results_data['completed']=completed
    with open(results_file,'w',encoding='utf-8') as wf:
        json.dump(results_data,wf,indent=4)


def build_resume_list(results_path,data_path):
    resume_list=[]
    filename2cnt={}
    result_data={}
    if not os.path.exists(results_path):
        return resume_list
    for file in os.listdir(results_path):
        if not file.endswith('.json'):
            continue
        file_path=os.path.join(results_path,file)
        try:
            with open(file_path,'r',encoding='utf-8') as f:
                result_data=json.load(f)
            is_completed=result_data.get('completed',False)
            batch_cnt=result_data.get('batch_cnt',0)
        except Exception as e:
            batch_cnt=0
        filename=file[:-len('_results.json')]
        filename2cnt[filename]=batch_cnt if not is_completed else -1

    for file in os.listdir(data_path):
        if not file.endswith('.jsonl'):
            continue
        filename=file[:-len('.jsonl')]
        resume_cnt=filename2cnt.get(filename,0)
        if resume_cnt!=-1:
            tp=result_data.get('batches',{}).get(f'batch_{resume_cnt}',{}).get('tp',0)
            fp=result_data.get('batches',{}).get(f'batch_{resume_cnt}',{}).get('fp',0)
            fn=result_data.get('batches',{}).get(f'batch_{resume_cnt}',{}).get('fn',0)
            metrics=[tp,fp,fn]
            resume_list.append((filename,resume_cnt,metrics))
    return resume_list


def process_batch(file_index,data_path,export_path,model,sampling_params,batch_size=1000,
                  batch_cnt=0,metrics=[0,0,0]):
    data_file=os.path.join(data_path,f'{file_index}.jsonl')
    rpath=os.path.join(export_path,f"{file_index}_results.json")
    detail_rpath=os.path.join(export_path,f"{file_index}_details.json")
    error_count=0
    if not os.path.exists(data_file):
        print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return
    skip=batch_cnt*batch_size
    dataset =datasets.load_dataset("json",data_files=data_file,streaming=True)
    iter=dataset['train']
    iter=iter.skip(skip)
    fn=metrics[2]
    fp=metrics[1]
    tp=metrics[0]
    for i,batch_items in enumerate(batched(iter,batch_size)):
        details={'DATE':[],'PERSON':[],'NORP':[],'GPE':[],'FAC':[],'TIME':[],'ORG':[],'LOC':[]}
        batch_index=batch_cnt+i+1
        error_count=0
        for item in batch_items:
            result={'DATE':[],'PERSON':[],'NORP':[],'GPE':[],'FAC':[],'TIME':[],'ORG':[],'LOC':[]}
            y_hat=create_y(item['entities'])
            try:
                texts=item['sentence'].strip().split('\n')
                batch_prompts=[create_jsonl_prompt(text) for text in texts if not is_only_special_chars(text) and len(text.strip())>0]
                batch_resp=model.generate(batch_prompts,sampling_params)
                for resp in batch_resp:
                    for r in resp.outputs:
                        jsonl_outputs=convert_to_jsonl(r.text)
                        for line in jsonl_outputs:
                            if line['label'] in ['PERSON','NORP','GPE','FAC','ORG','LOC']:
                                result[line['label']].append(line['value'].replace(' ',''))
                                details[line['label']].append(line['value'])
                metric=calculate_metrics(result,y_hat)
                tp += metric['tp']
                fp += metric['fp']
                fn += metric['fn']
                del texts, y_hat, batch_prompts, batch_resp, result,metric
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™: {e}")
                torch.cuda.empty_cache()
                error_count+=1
                continue
        recall= tp / (tp + fn) if (tp + fn) > 0 else 0
        precision= tp / (tp + fp) if (tp + fp) > 0 else 0
        f1= 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        res={
            'tp': tp,
            'fp': fp,
            'fn': fn,
            'recall': recall,
            'precision': precision,
            'f1': f1
        }
        update_results(rpath,res,batch_index,completed=False)
        update_results(detail_rpath,details,batch_index,completed=False)
        print(f'æ–‡ä»¶{file_index}.json - æ‰¹æ¬¡ {batch_index}å¤„ç†å®Œæˆ({len(batch_items)-error_count}/{len(batch_items)}) -- å·²å¤„ç† {batch_index*batch_size} æ¡æ•°æ®')
    update_results(rpath,None,None,completed=True)
    update_results(detail_rpath,None,None,completed=True)
    print(f'æ–‡ä»¶{file_index}.json å¤„ç†å®Œæˆ')
    torch.cuda.empty_cache()

def debug(data_path, model, sampling_params, debug_count=50):
    """
    è°ƒè¯•å‡½æ•°ï¼šå¤„ç†å‰Næ¡æ•°æ®ï¼Œæ˜¾ç¤ºè¯¦ç»†çš„ç”Ÿæˆæƒ…å†µ
    """
    print(f"=== å¼€å§‹è°ƒè¯•æ¨¡å¼ï¼Œå¤„ç†å‰ {debug_count} æ¡æ•°æ® ===")
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªjsonlæ–‡ä»¶
    data_files = [f for f in os.listdir(data_path) if f.endswith('.jsonl')]
    if not data_files:
        print("æ²¡æœ‰æ‰¾åˆ°.jsonlæ–‡ä»¶")
        return
    
    data_file = os.path.join(data_path, data_files[0])
    print(f"ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}")
    processed_count = 0
    error_count = 0
    try:
        dataset = datasets.load_dataset("json", data_files=data_file, streaming=True)
        iter_data = dataset['train']
        
        tp=0
        fp=0
        fn=0
        
        print("\n" + "="*80)
        print("å¼€å§‹é€æ¡å¤„ç†...")
        print("="*80)
        
        for i, item in enumerate(iter_data):
            if processed_count >= debug_count:
                break
                
            processed_count += 1
            print(f"\n--- ç¬¬ {processed_count} æ¡æ•°æ® ---")
            
            # æ˜¾ç¤ºåŸå§‹æ•°æ®
            print(f"åŸå§‹æ–‡æœ¬: {item['sentence'][:100]}..." if len(item['sentence']) > 100 else f"åŸå§‹æ–‡æœ¬: {item['sentence']}")
            
            # æ˜¾ç¤ºçœŸå®æ ‡ç­¾
            print("çœŸå®æ ‡ç­¾:")
            y_true = create_y(item['entities'])
            for label_type, entities in y_true.items():
                if entities:
                    print(f"  {label_type}: {entities}")
            
            try:
                # å¤„ç†æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«å¤šè¡Œï¼‰
                texts = item['sentence'].strip().split('\n')
                print(f"åˆ†å‰²åæ–‡æœ¬æ•°é‡: {len(texts)}")
                
                # ä¸ºæ¯ä¸ªæ–‡æœ¬åˆ›å»ºæç¤ºè¯
                batch_prompts = [create_jsonl_prompt(text) for text in texts if not is_only_special_chars(text) and len(text.strip()) > 0]
                
                # ç”Ÿæˆç»“æœ
                print("ç”Ÿæˆä¸­...")
                batch_resp = model.generate(batch_prompts, sampling_params)
                
                # è§£æç»“æœ
                result = {'DATE': [], 'PERSON': [], 'NORP': [], 'GPE': [], 'FAC': [], 'TIME': [], 'ORG': [], 'LOC': []}
                raw_outputs = []
                
                for j, resp in enumerate(batch_resp):
                    for r in resp.outputs:
                        raw_output = r.text.strip()
                        raw_outputs.append(raw_output)
                        print(f"  æ–‡æœ¬{j+1}åŸå§‹è¾“å‡º: {raw_output}")
                        
                        # è§£æJSONLè¾“å‡º
                        try:
                            jsonl_outputs = convert_to_jsonl(raw_output)
                            print(f"  æ–‡æœ¬{j+1}è§£æç»“æœ: {jsonl_outputs}")
                            
                            for line in jsonl_outputs:
                                if 'label' in line and 'value' in line:
                                    if line['label'] in ['PERSON', 'NORP', 'GPE', 'FAC', 'ORG', 'LOC']:
                                        result[line['label']].append(line['value'].replace(' ',''))
                        except Exception as parse_e:
                            print(f"  æ–‡æœ¬{j+1}è§£æå¤±è´¥: {parse_e}")
                
                # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                print("é¢„æµ‹æ ‡ç­¾:")
                for label_type, entities in result.items():
                    if entities:
                        print(f"  {label_type}: {entities}")
                
                # è®¡ç®—æŒ‡æ ‡
                metric = calculate_metrics(result, y_true)
                print(f"æŒ‡æ ‡ - TP: {metric['tp']}, FP: {metric['fp']}, FN: {metric['fn']}")
                
                tp += metric['tp']
                fp += metric['fp']
                fn += metric['fn']
                
                # æ¸…ç†å†…å­˜
                del texts, batch_prompts, batch_resp, result
                torch.cuda.empty_cache()
                
            except Exception as e:
                error_count += 1
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")
                torch.cuda.empty_cache()
                continue
            
            print("-" * 80)
            
            # æ¯10æ¡æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if processed_count % 10 == 0:
                print(f"\nğŸ“Š è¿›åº¦æŠ¥å‘Š: å·²å¤„ç† {processed_count}/{debug_count}")
        
        # æœ€ç»ˆç»Ÿè®¡
        print("\n" + "="*80)
        print("ğŸ¯ è°ƒè¯•å®Œæˆï¼æœ€ç»ˆç»Ÿè®¡:")
        print("="*80)
        print(f"æ€»å¤„ç†æ•°é‡: {processed_count}")
        recall= tp / (tp + fn) if (tp + fn) > 0 else 0
        precision= tp / (tp + fp) if (tp + fp) > 0 else 0
        f1= 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        print(f"æ€»TP: {tp}, æ€»FP: {fp}, æ€»FN: {fn}")
        print(f"ç²¾ç¡®ç‡: {precision:.4f}, å¬å›ç‡: {recall:.4f}, F1åˆ†æ•°: {f1:.4f}")
        
        if error_count > 0:
            print(f"\nâš ï¸ æœ‰ {error_count} æ¡æ•°æ®å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥:")
            print("1. æ¨¡å‹è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆJSONLè¦æ±‚")
            print("2. æç¤ºè¯æ˜¯å¦éœ€è¦ä¼˜åŒ–")
            print("3. æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®")
        
    except Exception as e:
        print(f"âŒ è°ƒè¯•å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    torch.cuda.empty_cache()
    gc.collect()
    args=parse_args()
    llm=LLM(model=args.model_path,tensor_parallel_size=args.tensor_parallel_size,seed=args.seed,gpu_memory_utilization=args.gpu_memory_utilization)
    sampling_params = SamplingParams(
    temperature=0,
    repetition_penalty=1.05,
    max_tokens=512,
    stop=["\n\n\n","###","```","python","<END>","<E>","<B>"],
    n=1
    )
    data_path=args.data_path
    export_path=args.export_path
    batch_size=args.batch_size
    
    # æ·»åŠ è°ƒè¯•æ¨¡å¼æ”¯æŒ
    import sys
    if '--debug' in sys.argv:
        print("ğŸ” å¯åŠ¨è°ƒè¯•æ¨¡å¼...")
        debug(data_path, llm, sampling_params, debug_count=10)
        exit(0)
    
    resume_list=build_resume_list(export_path,data_path)
    if not resume_list:
        print("æ²¡æœ‰å¾…å¤„ç†çš„æ–‡ä»¶")
        exit(0)
    print(f"å¾…å¤„ç†æ–‡ä»¶æ•°: {len(resume_list)}")
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    for file_index,resume_cnt,metrics in resume_list:
        print(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_index}.jsonl, ä»æ‰¹æ¬¡ {resume_cnt} ç»§ç»­")
        process_batch(file_index,data_path,export_path,llm,sampling_params,
                          batch_size=batch_size,batch_cnt=resume_cnt,metrics=metrics)
    

